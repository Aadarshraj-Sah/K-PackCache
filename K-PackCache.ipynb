{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrnIi3r1MFjk"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHxT2FIZVtVC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7ZtaUTDeZ-l"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D-dbwIn_ArN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxqR1AdN6AR6"
      },
      "outputs": [],
      "source": [
        "generated_results = []\n",
        "generated_results_2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8OHrRy8D23f"
      },
      "outputs": [],
      "source": [
        "ViralDataset2 = []\n",
        "ViralDataset3 = []\n",
        "ViralDataset4 = []\n",
        "SpotifyViral = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jStaf0R-tPE"
      },
      "outputs": [],
      "source": [
        "transfer_cost = 40\n",
        "caching_cost = 1\n",
        "expiry = 10\n",
        "alpha = 0.2\n",
        "max_clique_size = 5\n",
        "max_request_size = 5\n",
        "threshold = 0.2\n",
        "batch_size = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52xtuscwIglo",
        "outputId": "b6befc61-777a-4f23-ac5c-4b88833b79b9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DKELwt3MguZ"
      },
      "source": [
        "# NETFLIX DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFC9aTF4Mgua"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/Netflix4/netflix_viral_100_set_4.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ86f1ioMgua"
      },
      "outputs": [],
      "source": [
        "# df[['userid', 'dataid', 'timestamp', 'location']] = df['userid dataid timestamp location'].str.split(' ', 3, expand=True)\n",
        "\n",
        "# # Drop the original concatenated column\n",
        "# df.drop(columns=['userid dataid timestamp location'], inplace=True)\n",
        "\n",
        "# Convert 'userid' and 'dataid' columns to integers, and 'timestamp' to datetime\n",
        "df['userid'] = df['userid'].astype(int)\n",
        "df['dataid'] = df['dataid'].astype(int)\n",
        "df['timestamp'] = df['timestamp'].astype(int)\n",
        "df['location'] = df['location'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Czq8jiBFNNF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['dataid'].unique()\n",
        "\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['dataid'] = (df['dataid'].map(mapping_dict)).astype(int)\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM11UvETMgub"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "# Initialize the 3D array with zeros\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=object)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "    location = row['location']\n",
        "    timestamp = row['timestamp']\n",
        "    dataid = row['dataid']\n",
        "\n",
        "    if(dataid == 0):\n",
        "      continue\n",
        "\n",
        "    # Check if the current list would exceed max_request_size\n",
        "    if isinstance(result_array[location, timestamp], list) and len(result_array[location, timestamp]) >= max_request_size:\n",
        "        # If it exceeds, ignore this element\n",
        "        continue\n",
        "\n",
        "    if result_array[location, timestamp] == 0:  # If the cell is empty\n",
        "        result_array[location, timestamp] = [dataid]  # Initialize as a list\n",
        "    else:\n",
        "        result_array[location, timestamp].append(dataid)  # Append to existing list\n",
        "\n",
        "# Convert empty cells to None for uniformity\n",
        "result_array[result_array == 0] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmK9gx0mMguc"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikxhJsB0W869",
        "outputId": "2a5ba876-648d-499b-d1c2-52e4e0129ddf"
      },
      "outputs": [],
      "source": [
        "num_requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm3pa7wzTkjO"
      },
      "source": [
        "# NETFLIX DATASET OLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9ePS_XjWtCk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/adarsh_sweeya_netflix_2_sem8.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azGoZRKKguiV"
      },
      "outputs": [],
      "source": [
        "# df[['userid', 'dataid', 'timestamp', 'location']] = df['userid dataid timestamp location'].str.split(' ', 3, expand=True)\n",
        "\n",
        "# # Drop the original concatenated column\n",
        "# df.drop(columns=['userid dataid timestamp location'], inplace=True)\n",
        "\n",
        "# Convert 'userid' and 'dataid' columns to integers, and 'timestamp' to datetime\n",
        "df['userid'] = df['userid'].astype(int)\n",
        "df['dataid'] = df['dataid'].astype(int)\n",
        "df['timestamp'] = df['timestamp'].astype(int)\n",
        "df['location'] = df['location'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bOXyCK8iDVH"
      },
      "outputs": [],
      "source": [
        "min_dataid = min(df['dataid'])-1\n",
        "\n",
        "# df['location'] = (df['location'] / 1000).astype(int)\n",
        "df['dataid'] = (df['dataid'] - min_dataid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLm7W5lAaRnC",
        "outputId": "dfe0866b-1965-4a96-c92e-aa19c8aadfa6"
      },
      "outputs": [],
      "source": [
        "temp=min(df['location'])\n",
        "temp2=max(df['location'])\n",
        "print(temp)\n",
        "print(temp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAspeikaocsB",
        "outputId": "ad75cfa7-9e44-4273-c153-54fef45657e7"
      },
      "outputs": [],
      "source": [
        "min(df['dataid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8AfMASEl7Lv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=int)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "  location = row['location']\n",
        "  timestamp = row['timestamp']\n",
        "  dataid = row['dataid']\n",
        "  result_array[location, timestamp] = dataid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zr9jEBdSpkA",
        "outputId": "7f39fad9-ef98-420b-b591-a30311b0d54e"
      },
      "outputs": [],
      "source": [
        "num_timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xCoUmIo53Xq"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J1vNpgb__7S"
      },
      "source": [
        "# Spotify Dataset Viral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JimbN8YR__7S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/viral_100.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmHfo7na__7T",
        "outputId": "b198386b-f646-43fa-9a65-b44c58c79a6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sort the DataFrame by 'plays' in descending order\n",
        "df.sort_values(['location', 'timestamp', 'plays'], ascending=[True, True, False], inplace=True)\n",
        "\n",
        "# Keep only the rows with the maximum 'plays' for each group of 'location' and 'timestamp'\n",
        "# result_df = df.groupby(['location', 'timestamp']).first().reset_index()\n",
        "\n",
        "# result_df = result_df.drop(['plays'], axis=1)\n",
        "\n",
        "\n",
        "# Display the result\n",
        "# print(result_df.head(100))\n",
        "\n",
        "\n",
        "# print(\"Count of Unique Locations:\", result_df['location'].nunique())\n",
        "print(\"Count of Unique Data IDs:\", df['dataid'].nunique())\n",
        "# print(\"Count of Unique Timestamps:\", result_df['timestamp'].nunique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsC4lJQCGTZ3",
        "outputId": "6debb2e6-9d2b-48af-8b63-1cbdaeff2e98"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['dataid'].unique()\n",
        "\n",
        "print(unique_dataids)\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "print(unique_dataids)\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['dataid'] = (df['dataid'].map(mapping_dict)).astype(int)\n",
        "\n",
        "print(df['dataid'])\n",
        "\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B20ZGIzJH38A",
        "outputId": "f2446b17-4ff2-4ab4-e931-44324d93b180"
      },
      "outputs": [],
      "source": [
        "df['dataid'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZCWtygiGJoo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['location'].unique()\n",
        "\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['location'] = (df['location'].map(mapping_dict)).astype(int)\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwm3S9alLCjm",
        "outputId": "1727bb4a-860e-4dbd-e1f4-674b4a5d98fc"
      },
      "outputs": [],
      "source": [
        "df['location'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtWy0Xof__7T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "# Initialize the 3D array with zeros\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=object)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "    location = row['location']\n",
        "    timestamp = row['timestamp']\n",
        "    dataid = row['dataid']\n",
        "\n",
        "    if(dataid == 0):\n",
        "      continue\n",
        "\n",
        "    # Check if the current list would exceed max_request_size\n",
        "    if isinstance(result_array[location, timestamp], list) and len(result_array[location, timestamp]) >= max_request_size:\n",
        "        # If it exceeds, ignore this element\n",
        "        continue\n",
        "\n",
        "    if result_array[location, timestamp] == 0:  # If the cell is empty\n",
        "        result_array[location, timestamp] = [dataid]  # Initialize as a list\n",
        "    else:\n",
        "        result_array[location, timestamp].append(dataid)  # Append to existing list\n",
        "\n",
        "# Convert empty cells to None for uniformity\n",
        "result_array[result_array == 0] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLajEAM_MJcZ",
        "outputId": "6ebd58b7-be0a-4d39-a483-c3684661eae8"
      },
      "outputs": [],
      "source": [
        "num_timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8lQ9uCyMM_n",
        "outputId": "dcbb95cb-1ee3-4178-c0c2-8f08b5ad3c7f"
      },
      "outputs": [],
      "source": [
        "max_z_dim = 0\n",
        "max_location = None\n",
        "max_timestamp = None\n",
        "\n",
        "# Iterate through the result_array to find the maximum z dimension\n",
        "for i in range(num_locations):\n",
        "    for j in range(num_timestamps):\n",
        "        if isinstance(result_array[i, j], list):\n",
        "            z_dim = len(result_array[i, j])\n",
        "            if z_dim > max_z_dim:\n",
        "                max_z_dim = z_dim\n",
        "                max_location = i\n",
        "                max_timestamp = j\n",
        "\n",
        "print(\"Maximum z dimension:\", max_z_dim)\n",
        "print(\"Corresponding location:\", max_location)\n",
        "print(\"Corresponding timestamp:\", max_timestamp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Bx_5l-__7T"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KaPPUHo__7T",
        "outputId": "ccdf4dad-9254-4c51-c516-32421612e5ab"
      },
      "outputs": [],
      "source": [
        "num_requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0wzZVL__7T",
        "outputId": "2e8f4922-1c9a-477b-fe85-3a8a9a634d01"
      },
      "outputs": [],
      "source": [
        "num_data_pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZSQs0wd__7T",
        "outputId": "e4afdb81-e569-40f0-f44c-0876c6caa3e5"
      },
      "outputs": [],
      "source": [
        "num_servers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRuVTtULj5nY"
      },
      "source": [
        "# Spotify Dataset Old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3RA66NHmJSu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/spotify.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HET0Ts3wmzzW",
        "outputId": "0df10705-0ba8-4d67-880e-324a4f918d41"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sort the DataFrame by 'plays' in descending order\n",
        "df.sort_values(['location', 'timestamp', 'plays'], ascending=[True, True, False], inplace=True)\n",
        "\n",
        "# Keep only the rows with the maximum 'plays' for each group of 'location' and 'timestamp'\n",
        "result_df = df.groupby(['location', 'timestamp']).first().reset_index()\n",
        "\n",
        "result_df = result_df.drop(['plays'], axis=1)\n",
        "\n",
        "\n",
        "# Display the result\n",
        "print(result_df.head(100))\n",
        "\n",
        "\n",
        "print(\"Count of Unique Locations:\", result_df['location'].nunique())\n",
        "print(\"Count of Unique Data IDs:\", result_df['dataid'].nunique())\n",
        "print(\"Count of Unique Timestamps:\", result_df['timestamp'].nunique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsT8dA_Bt946"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=int)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "    location = row['location']\n",
        "    timestamp = row['timestamp']\n",
        "    dataid = row['dataid']\n",
        "    result_array[location, timestamp] = dataid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUo20TXquFKB"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGDeaePSzAZb",
        "outputId": "ed172e85-2e0c-450a-eb7a-a7f4a70d9a33"
      },
      "outputs": [],
      "source": [
        "num_requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8RtvlHmzEOn",
        "outputId": "ba03e557-e6fa-407f-cb4a-338f4c281a63"
      },
      "outputs": [],
      "source": [
        "num_data_pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnjwaP8AzG9g",
        "outputId": "fefebd85-6dc3-4123-9048-2f1ffa779971"
      },
      "outputs": [],
      "source": [
        "num_servers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAIWxCHHTtGi"
      },
      "source": [
        "# GENERATED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwyGdea85q8e"
      },
      "outputs": [],
      "source": [
        "num_requests = 1000\n",
        "num_data_pts = 40\n",
        "num_servers = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivmKgfEz6x91"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean = 20\n",
        "std_dev_percent = 0.20  # 20% standard deviation\n",
        "\n",
        "std_dev = (num_data_pts) * std_dev_percent\n",
        "requests = np.zeros((num_servers, num_requests))\n",
        "\n",
        "for idx, el in enumerate(requests):\n",
        "  # Generate random data following a normal distribution\n",
        "  random_data = np.random.normal(mean, std_dev, num_requests)\n",
        "\n",
        "  # Ensure that values are within the specified range\n",
        "  random_data = np.clip(random_data, 0, num_data_pts)\n",
        "  random_data = random_data.astype(int)\n",
        "  requests[idx]=random_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1lxuUAB2ZET"
      },
      "outputs": [],
      "source": [
        "flattened_requests = requests.flatten()\n",
        "\n",
        "# Count the frequency of each number using a dictionary\n",
        "frequency_dict = {}\n",
        "for num in flattened_requests:\n",
        "    if num in frequency_dict:\n",
        "        frequency_dict[num] += 1\n",
        "    else:\n",
        "        frequency_dict[num] = 1\n",
        "\n",
        "# Extract the frequencies in sorted order\n",
        "numbers, frequencies = zip(*sorted(frequency_dict.items()))\n",
        "\n",
        "# Plot the frequency as a bar graph\n",
        "# plt.bar(numbers, frequencies)\n",
        "# plt.xlabel('Number')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.title('Frequency of Numbers in Requests')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fVZVOYJ127j"
      },
      "source": [
        "# gen dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJbP9hqEg_PR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_servers = 10\n",
        "num_requests = 1000\n",
        "num_data_pts = 40\n",
        "\n",
        "dataset = [[] for _ in range(num_servers)]\n",
        "\n",
        "while any(len(server_data) < num_requests for server_data in dataset):\n",
        "    x = int(random.normalvariate(20, 5))  # Adjust the standard deviation as needed\n",
        "    y = int(random.normalvariate(20, 5))\n",
        "\n",
        "    # Ensure x and y are within [1, 40]\n",
        "    x, y = max(1, min(x, 40)), max(1, min(y, 40))\n",
        "    x, y = min(x, y), max(x, y)\n",
        "\n",
        "    for server in range(num_servers):\n",
        "      f = random.randint(1, 20)\n",
        "      for req_idx in range(f):\n",
        "        t = random.randint(1, max_request_size)\n",
        "        request=[random.randint(x, y) for _ in range(t)]\n",
        "        dataset[server].append(request)\n",
        "\n",
        "for server in range(num_servers):\n",
        "  dataset[server]=dataset[server][:num_requests]\n",
        "\n",
        "requests = dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVucgwDoi11m",
        "outputId": "0e1959ec-a360-4cb1-c454-96f9c12d7689"
      },
      "outputs": [],
      "source": [
        "for i in range(0, num_servers):\n",
        "  for el in range(0, 10):\n",
        "    print(requests[i][el])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZTgBjxTwjUd"
      },
      "source": [
        "# NO PACKING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4oa05EeBMFJ"
      },
      "outputs": [],
      "source": [
        "# NO PACKING\n",
        "\n",
        "def no_packing(expiry):\n",
        "  local_present = np.full((num_servers, num_data_pts), -1, dtype = int)\n",
        "  total_cost = 0\n",
        "  for i in range(0, num_requests):\n",
        "    for j in range(0, num_servers):\n",
        "      if not requests[j][i]:\n",
        "        continue\n",
        "      for k in range(len(requests[j][i])):\n",
        "        flag = requests[j][i][k]\n",
        "        if flag == 0:\n",
        "          continue\n",
        "        flag -= 1\n",
        "        if local_present[j][int(flag)] < i :   # if not present locally in the server\n",
        "          local_present[j][int(flag)] = i + expiry\n",
        "          total_cost += transfer_cost\n",
        "          total_cost+=caching_cost*expiry\n",
        "  return total_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fptZF-2SwTob"
      },
      "source": [
        "# TWO DATA POINTS CACHE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XQ3SyXrbuDt"
      },
      "outputs": [],
      "source": [
        "# TWO DATA POINTS CACHE\n",
        "\n",
        "correlation_matrix = np.zeros((num_data_pts,num_data_pts))\n",
        "total_cost_2 = 0\n",
        "main_server_transfer = np.zeros(num_data_pts, dtype = bool)\n",
        "local_present = np.zeros((num_servers, num_data_pts), dtype = int)\n",
        "\n",
        "for j in range(0, num_servers):\n",
        "  for i in range(1,num_requests):\n",
        "    if not requests[j][i]:\n",
        "      continue\n",
        "    for k1 in range(len(requests[j][i])):\n",
        "      for k2 in range(k1):\n",
        "        flag1 = int(requests[j][i][k1])-1\n",
        "        flag2 = int(requests[j][i][k2])-1\n",
        "        if flag1 == -1 or flag2 == -1:\n",
        "          continue\n",
        "        correlation_matrix[flag1][flag2]+=1\n",
        "        correlation_matrix[flag2][flag1]+=1\n",
        "\n",
        "for i in range(0, num_data_pts):\n",
        "  correlation_matrix[i][i]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo2Oe2z_bzSU",
        "outputId": "7043d557-9b67-4e93-8b06-cd1572dd87e0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "normalized_array = correlation_matrix.copy()\n",
        "threshold = 0.7\n",
        "\n",
        "# threshold_value= np.percentile(correlation_matrix, threshold*100)\n",
        "# for i, el in enumerate(normalized_array):\n",
        "#   el[el<threshold_value] = 0\n",
        "#   el[el>=threshold_value] = 1\n",
        "\n",
        "normalized_array = (correlation_matrix - correlation_matrix.min()) / (correlation_matrix.max() - correlation_matrix.min())\n",
        "for i, el in enumerate(normalized_array):\n",
        "  el[el<threshold] = 0\n",
        "  el[el>=threshold] = 1\n",
        "\n",
        "packing = np.full(num_data_pts, -1)\n",
        "for i in range(0, num_data_pts):\n",
        "  if packing[i]!=-1:\n",
        "    continue\n",
        "  for j in range(0, num_data_pts):\n",
        "    # print(i, j, normalized_array[i][j], packing[j])\n",
        "    if normalized_array[i][j]==1 and packing[j]==-1:\n",
        "      packing[i]=j\n",
        "      packing[j]=i\n",
        "      break\n",
        "\n",
        "# for i in normalized_array:\n",
        "#   print(i)\n",
        "\n",
        "# for i in packing:\n",
        "#   print(i)\n",
        "\n",
        "print((packing!=-1).sum())\n",
        "\n",
        "# ax = sns.heatmap(normalized_array, linewidth=0.5, cmap=\"crest\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPcEgLF67rrk",
        "outputId": "1cdf96f9-c367-4f00-b5cd-8f5a349c25dc"
      },
      "outputs": [],
      "source": [
        "for idx, el in enumerate(packing):\n",
        "  if el!=-1:\n",
        "    print(idx, el)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE0N_LMgeqLZ"
      },
      "outputs": [],
      "source": [
        "for i in range(0, num_requests):\n",
        "  temp_transfer = main_server_transfer.copy()\n",
        "  for j in range(0, num_servers):\n",
        "    if not requests[j][i]:\n",
        "      continue\n",
        "    for k in range(len(requests[j][i])):\n",
        "      flag = int(requests[j][i][k])\n",
        "      if flag == 0:\n",
        "        continue\n",
        "      flag -= 1\n",
        "      if local_present[j][flag] <= i :   # if not present locally in the server\n",
        "        flag_pair = int(packing[flag])\n",
        "        if flag_pair == -1:\n",
        "          if main_server_transfer[flag] == True:  # if transferred from the main server\n",
        "            total_cost_2 += transfer_cost\n",
        "          else:  # if not present in any local servers\n",
        "            total_cost_2 += main_server_transfer_cost\n",
        "            temp_transfer[flag] = True\n",
        "        else:\n",
        "          if main_server_transfer[flag] == True and main_server_transfer[flag_pair] == True:  # if transferred from the main server\n",
        "            total_cost_2 += (1+alpha)*transfer_cost\n",
        "          else:  # if not present in any local servers\n",
        "            total_cost_2 += (1+alpha)*main_server_transfer_cost\n",
        "            temp_transfer[flag] = True\n",
        "            temp_transfer[flag_pair] = True\n",
        "          local_present[j][flag_pair] = i\n",
        "        local_present[j][flag] = i\n",
        "      else:\n",
        "        total_cost_2+=caching_cost*(i-local_present[j][flag])\n",
        "        local_present[j][flag] = i\n",
        "  main_server_transfer = main_server_transfer|temp_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtVWxp2l62RL",
        "outputId": "6b647f6a-5114-4186-8831-04357dec80a1"
      },
      "outputs": [],
      "source": [
        "total_cost_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRYspxXePbyY"
      },
      "source": [
        "# K POINTS PACKING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm3pr9BQ31N-"
      },
      "outputs": [],
      "source": [
        "def construct_correlation_matrix():\n",
        "  correlation_matrix = np.zeros((num_data_pts,num_data_pts))\n",
        "\n",
        "  for j in range(0, num_servers):\n",
        "    for i in range(1,num_requests):\n",
        "      if not requests[j][i]:\n",
        "        continue\n",
        "      for k1 in range(1, len(requests[j][i])):\n",
        "        for k2 in range(k1):\n",
        "          flag1 = int(requests[j][i][k1])-1\n",
        "          flag2 = int(requests[j][i][k2])-1\n",
        "          if flag1 == -1 or flag2 == -1:\n",
        "            continue\n",
        "          correlation_matrix[flag1][flag2]+=1\n",
        "          correlation_matrix[flag2][flag1]+=1\n",
        "\n",
        "  for i in range(0, num_data_pts):\n",
        "    correlation_matrix[i][i]=0\n",
        "\n",
        "  normalized_array = (correlation_matrix - correlation_matrix.min()) / (correlation_matrix.max() - correlation_matrix.min())\n",
        "\n",
        "  return normalized_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZcbtcD3kpJg"
      },
      "outputs": [],
      "source": [
        "from queue import Queue\n",
        "\n",
        "def split_clique(G, clique, max_clique_size, weighted_adj_matrix):\n",
        "    if len(clique) <= max_clique_size:\n",
        "        return [clique]\n",
        "\n",
        "    # Sort edges within the clique by their weights\n",
        "    weighted_edges = [(u, v, weighted_adj_matrix[u][v]) for u in clique for v in clique if u < v and weighted_adj_matrix[u][v] != 0]\n",
        "    weighted_edges.sort(key=lambda x: x[2])\n",
        "\n",
        "    resulting_cliques = []\n",
        "    queue = Queue()\n",
        "    queue.put(clique)\n",
        "\n",
        "    while not queue.empty():\n",
        "        curr_clique = queue.get()\n",
        "        # Remove the least weighted edge\n",
        "        if not weighted_edges:\n",
        "          break\n",
        "        u, v, _ = weighted_edges.pop(0)\n",
        "        if G.has_edge(u, v):\n",
        "          G.remove_edge(u, v)\n",
        "        else:\n",
        "          continue\n",
        "        # Recalculate connected components to split the clique\n",
        "        components = list(nx.find_cliques(G.subgraph(curr_clique)))\n",
        "        if len(components) > 1:\n",
        "            for component in components:\n",
        "                if len(component) > max_clique_size:\n",
        "                    queue.put(list(component))\n",
        "                else:\n",
        "                    resulting_cliques.append(list(component))\n",
        "        else:\n",
        "          queue.put(curr_clique)\n",
        "    return resulting_cliques\n",
        "\n",
        "def find_cliques_with_max_size(G, max_clique_size, weighted_adj_matrix):\n",
        "    cliques = list(nx.find_cliques(G))\n",
        "    modified_cliques = []\n",
        "    for clique in cliques:\n",
        "        modified_cliques.extend(split_clique(G, clique, max_clique_size, weighted_adj_matrix))\n",
        "    return modified_cliques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qadP0h0u9dEm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "\n",
        "# independent_cliques = []\n",
        "\n",
        "def k_packing(threshold, alpha, expiry, max_clique_size):\n",
        "  normalized_array = construct_correlation_matrix()\n",
        "  new_normalized_array = normalized_array.copy()\n",
        "  for i, el in enumerate(normalized_array):\n",
        "    el[el<threshold] = 0\n",
        "    el[el>=threshold] = 1\n",
        "\n",
        "  for i, el in enumerate(new_normalized_array):\n",
        "    el[el<threshold] = 0\n",
        "  packing = normalized_array.copy()\n",
        "  total_cost_k = 0\n",
        "  local_present = np.full((num_servers, num_data_pts), -1, dtype = int)\n",
        "\n",
        "  G = nx.Graph(packing)\n",
        "  cliques = find_cliques_with_max_size(G, max_clique_size, new_normalized_array)\n",
        "  all_cliques = sorted(cliques, key=len, reverse=True)\n",
        "\n",
        "  new_cliques = set()\n",
        "  for clique in all_cliques:\n",
        "    for r in range(2, len(clique)+1):\n",
        "        new_cliques.update(combinations(clique, r))\n",
        "  all_cliques= list(new_cliques)\n",
        "  all_cliques = sorted(list(all_cliques), key=len, reverse=True)\n",
        "\n",
        "  independent_cliques = []\n",
        "  for clique in all_cliques:\n",
        "      is_disjoint = all(set(clique).isdisjoint(selected_clique) for selected_clique in independent_cliques)\n",
        "      if is_disjoint:\n",
        "          independent_cliques.append(clique)\n",
        "\n",
        "  # Print the cliques by size\n",
        "  # for size in range(1, max_clique_size+1):\n",
        "  #   cliques_of_size = [clique for clique in independent_cliques if len(clique) == size]\n",
        "  #   clique_graph.append(len(cliques_of_size))\n",
        "    # print(f\"Cliques of size {size}:\", cliques_of_size)\n",
        "\n",
        "  # for size in range(1, max_clique_size+1):\n",
        "  #   cliques_of_size = [clique for clique in independent_cliques if len(clique) == size]\n",
        "  #   print(f\"Cliques of size {size}:\", cliques_of_size)\n",
        "\n",
        "  for i in range(0, num_requests):\n",
        "    for j in range(0, num_servers):\n",
        "      if not requests[j][i]:\n",
        "        continue\n",
        "      for k in range(len(requests[j][i])):\n",
        "        flag = int(requests[j][i][k])\n",
        "        if flag == 0:\n",
        "          continue\n",
        "        flag -= 1\n",
        "        if local_present[j][flag] < i :   # if not present locally in the server\n",
        "          clique_present = [flag]\n",
        "          for idx, clique in enumerate(independent_cliques):\n",
        "            if flag in clique:\n",
        "              clique_present = clique\n",
        "              break\n",
        "          clique_len = len(clique_present)\n",
        "          for el in clique_present:\n",
        "            local_present[j][el]= i+expiry\n",
        "          total_cost_k += (1+(clique_len-1)*alpha)*transfer_cost\n",
        "          total_cost_k+=caching_cost*expiry*clique_len\n",
        "\n",
        "  return total_cost_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWlVAh27PkbW"
      },
      "outputs": [],
      "source": [
        "# output = k_packing(threshold, alpha, expiry, max_clique_size)\n",
        "\n",
        "# # # Initialize node colors to a default color (e.g., white)\n",
        "# node_colors = {node: '#F0F0F0' for node in G.nodes}\n",
        "\n",
        "# # Assign a unique color to each clique\n",
        "# for i, clique in enumerate(independent_cliques):\n",
        "#     color = \"#{:06x}\".format(random.randint(0, 0xFFFFFF))  # Generate a random color\n",
        "#     for node in clique:\n",
        "#         node_colors[node] = color\n",
        "\n",
        "# # Plot the graph with node colors\n",
        "# nx.draw_random(G, with_labels=True, font_weight='bold', node_color=[node_colors[node] for node in G.nodes])\n",
        "# plt.savefig(\"clique.pdf\")\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mtv3-FaHInQ"
      },
      "outputs": [],
      "source": [
        "# k_packing(threshold, alpha, 10, 4)\n",
        "# print((100*(total_cost-total_cost_k))/total_cost)\n",
        "# generated_results.append((100*(total_cost-total_cost_k))/total_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzgBpbaNEokt"
      },
      "source": [
        "# Online K Packing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wInRky4VEuTn"
      },
      "outputs": [],
      "source": [
        "def online_k_packing(batch_size, threshold, alpha, expiry, max_clique_size):\n",
        "  total_cost_online = 0\n",
        "  local_present = np.full((num_servers, num_data_pts), -1, dtype = int)\n",
        "  independent_cliques = []\n",
        "\n",
        "  correlation_matrix = np.zeros((num_data_pts,num_data_pts))\n",
        "  correlation_matrix_copy = np.zeros((num_data_pts,num_data_pts))\n",
        "\n",
        "  for i in range(0, num_requests):\n",
        "    for j in range(0, num_servers):\n",
        "      if not requests[j][i]:\n",
        "        continue\n",
        "      if i>batch_size:    # removing from the correlation matrix\n",
        "        if not requests[j][i-batch_size]:\n",
        "          continue\n",
        "        for k2 in range(len(requests[j][i-batch_size])):\n",
        "          for k1 in range(k2):\n",
        "            temp1 = int(requests[j][i-batch_size][k2])-1\n",
        "            temp2 = int(requests[j][i-batch_size][k1])-1\n",
        "            if(temp1!=-1 and temp2!=-1):\n",
        "              correlation_matrix_copy[temp1][temp2]-=1\n",
        "              correlation_matrix_copy[temp2][temp1]-=1\n",
        "      for k in range(len(requests[j][i])):\n",
        "        flag1 = int(requests[j][i][k])-1\n",
        "        if flag1 == -1:\n",
        "          continue\n",
        "        if i < batch_size:\n",
        "          if local_present[j][int(flag1)] < i :   # if not present locally in the server\n",
        "            local_present[j][int(flag1)] = i + expiry\n",
        "            total_cost_online += transfer_cost\n",
        "            total_cost_online += caching_cost*expiry\n",
        "        else:\n",
        "          if local_present[j][flag1] < i:   # if not present locally in the server\n",
        "            clique_present = [flag1]\n",
        "            for clique in independent_cliques:\n",
        "              if flag1 in clique:\n",
        "                clique_present = clique\n",
        "                break\n",
        "            clique_len = len(clique_present)\n",
        "            for el in clique_present:\n",
        "              local_present[j][el]= i+expiry\n",
        "            total_cost_online += (1+(clique_len-1)*alpha)*transfer_cost\n",
        "            total_cost_online+=caching_cost*expiry*clique_len\n",
        "\n",
        "        # adding to the correlation matrix\n",
        "        for k1 in range(k):\n",
        "          flag2 = int(requests[j][i][k1])-1\n",
        "          if flag1 != -1 and flag2 != -1:\n",
        "            correlation_matrix_copy[flag1][flag2]+=1\n",
        "            correlation_matrix_copy[flag2][flag1]+=1\n",
        "\n",
        "        if (i+1) % batch_size == 0:\n",
        "          correlation_matrix = correlation_matrix_copy[:]\n",
        "          normalized_array = (correlation_matrix - correlation_matrix.min()) / (correlation_matrix.max() - correlation_matrix.min())\n",
        "          new_normalized_array = (correlation_matrix - correlation_matrix.min()) / (correlation_matrix.max() - correlation_matrix.min())\n",
        "          for el in normalized_array:\n",
        "            el[el<threshold] = 0\n",
        "            el[el>=threshold] = 1\n",
        "          for el in new_normalized_array:\n",
        "            el[el<threshold] = 0\n",
        "          G = nx.Graph(normalized_array)\n",
        "          cliques = find_cliques_with_max_size(G, max_clique_size, new_normalized_array)\n",
        "          all_cliques = sorted(cliques, key=len, reverse=True)\n",
        "          new_cliques = set()\n",
        "          for clique in all_cliques:\n",
        "            for r in range(2, len(clique)+1):\n",
        "                new_cliques.update(combinations(clique, r))\n",
        "          all_cliques= list(new_cliques)\n",
        "          all_cliques = sorted(list(all_cliques), key=len, reverse=True)\n",
        "          independent_cliques = []\n",
        "          for clique in all_cliques:\n",
        "              is_disjoint = all(set(clique).isdisjoint(selected_clique) for selected_clique in independent_cliques)\n",
        "              if is_disjoint:\n",
        "                  independent_cliques.append(clique)\n",
        "  return total_cost_online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkbKhjebEx7f"
      },
      "outputs": [],
      "source": [
        "# total_cost_online = online_k_packing(batch_size, 0.001, alpha, expiry)\n",
        "# print(100*(total_cost-total_cost_k)/total_cost)\n",
        "# print(100*(total_cost-total_cost_online)/total_cost)\n",
        "# generated_results_2.append(100*(total_cost-total_cost_online)/total_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnJI84cVC7i_"
      },
      "source": [
        "# Graph plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQFzMb_HG8n"
      },
      "source": [
        "## threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqSC7f_DDB5g"
      },
      "outputs": [],
      "source": [
        "values = [0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]\n",
        "generated_results = []\n",
        "generated_results_2 = []\n",
        "total_cost=no_packing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNza4JJHBTzI"
      },
      "outputs": [],
      "source": [
        "for threshold_elmt in values:\n",
        "  total_cost_k = k_packing(threshold_elmt, alpha, expiry, max_clique_size)\n",
        "  generated_results.append((100*(total_cost-total_cost_k))/total_cost)\n",
        "  total_cost_online = online_k_packing(batch_size, threshold_elmt, alpha, expiry)\n",
        "  generated_results_2.append(100*(total_cost-total_cost_online)/total_cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Rr2HxcvkH-gx",
        "outputId": "b7c93d41-3b7c-4b11-aeff-023842c8c510"
      },
      "outputs": [],
      "source": [
        "print(generated_results)\n",
        "print(generated_results_2)\n",
        "# [2.9832285115303985, 4.3584905660377355, 7.330188679245283, 11.254716981132075, 11.58700209643606, 11.618448637316561, 11.639412997903564, 11.219077568134171, 9.9958071278826, 10.39412997903564, 10.044025157232705, 9.582809224318659]\n",
        "# [-2.8144654088050314, 3.109014675052411, 7.832285115303983, 5.638364779874214, 7.3930817610062896, 8.423480083857442, 8.530398322851154, 8.135220125786164, 9.116352201257861, 7.387840670859539, 8.573375262054507, 7.733752620545073]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UK3LkeQQGXfD",
        "outputId": "672de214-35ca-48b1-8801-db172655f6c4"
      },
      "outputs": [],
      "source": [
        "# 200 tasks const, processors vs penalty\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook\n",
        "\n",
        "x = values\n",
        "y = generated_results\n",
        "y1 = generated_results_2\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "# plotting the points\n",
        "f = plt.figure()\n",
        "f.set_figwidth(7)\n",
        "f.set_figheight(3)\n",
        "plt.plot(x, y, color='g',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Offline', linestyle='dotted')\n",
        "\n",
        "plt.plot(x, y1, color='magenta',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Online',linestyle='dashed')\n",
        "\n",
        "\n",
        "plt.ylabel('Profit percentage')\n",
        "plt.xlabel('Threshold')\n",
        "plt.title('Profit Percentage vs Threshold for Spotify Dataset',color=\"black\")\n",
        "plt.legend(fontsize=12,edgecolor='k',ncol=2)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HePRjNVlF3a"
      },
      "outputs": [],
      "source": [
        "plt.savefig(\"threshold_spotify.pdf\", bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfl-tojQKCyc"
      },
      "source": [
        "## alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rkz0Q09SKGvO",
        "outputId": "fc78a765-a98a-406e-c513-a8d17fd70c3b"
      },
      "outputs": [],
      "source": [
        "values = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4]\n",
        "generated_results = []\n",
        "generated_results_2 = []\n",
        "total_cost=no_packing()\n",
        "\n",
        "for elmt in values:\n",
        "  total_cost_k = k_packing(threshold, elmt, expiry, max_clique_size)\n",
        "  generated_results.append((100*(total_cost-total_cost_k))/total_cost)\n",
        "  total_cost_online = online_k_packing(batch_size, threshold, elmt, expiry)\n",
        "  generated_results_2.append(100*(total_cost-total_cost_online)/total_cost)\n",
        "\n",
        "print(generated_results)\n",
        "print(generated_results_2)\n",
        "# [24.063862660944206, 20.838454935622316, 17.61304721030043, 14.387639484978541, 11.162231759656652, 7.936824034334764, 4.711416309012876, 1.486008583690987]\n",
        "# [13.203090128755365, 11.549527896995707, 9.895965665236051, 8.242403433476396, 6.588841201716738, 4.935278969957081, 3.281716738197425, 1.6281545064377683]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XpC7YbfcR_PO",
        "outputId": "b51f345d-9eb7-480b-b6a3-52e32ec029f6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = values\n",
        "y = generated_results\n",
        "y1 = generated_results_2\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "# plotting the points\n",
        "f = plt.figure()\n",
        "f.set_figwidth(7)\n",
        "f.set_figheight(3)\n",
        "plt.plot(x, y, color='g',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Offline', linestyle='dotted')\n",
        "\n",
        "plt.plot(x, y1, color='magenta',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Online',linestyle='dashed')\n",
        "\n",
        "\n",
        "plt.ylabel('Profit percentage')\n",
        "plt.xlabel('Alpha')\n",
        "plt.title('Profit Percentage vs Alpha',color=\"black\")\n",
        "plt.legend(fontsize=12,edgecolor='k',ncol=2)\n",
        "\n",
        "plt.savefig(\"alpha.pdf\",bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz4eJzg-LCow"
      },
      "source": [
        "## clique size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "1Ug_fgHZLKjq",
        "outputId": "117f6925-d6a2-4537-c3fb-c9b752334240"
      },
      "outputs": [],
      "source": [
        "clique_graph = []\n",
        "values = range(1,7)\n",
        "k_packing(threshold, alpha, expiry, 6)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(values, clique_graph)\n",
        "\n",
        "plt.xlabel('Clique Size')\n",
        "plt.ylabel('Number of Cliques')\n",
        "plt.title('Frequency of Cliques vs Clique Size')\n",
        "\n",
        "plt.savefig(\"cliquesize3.pdf\",bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "32y3F2ZOQ5I4",
        "outputId": "fdf7b74d-4522-4fde-df2a-3183c17b21fa"
      },
      "outputs": [],
      "source": [
        "max_values = range(3,10)\n",
        "generated_results=[]\n",
        "\n",
        "total_cost=no_packing(expiry)\n",
        "\n",
        "for elmt in max_values:\n",
        "  total_cost_k = k_packing(threshold, alpha, expiry, elmt)\n",
        "  generated_results.append((100*(total_cost-total_cost_k))/total_cost)\n",
        "\n",
        "plt.bar(max_values, generated_results)\n",
        "\n",
        "plt.xlabel('Maximum Clique Size')\n",
        "plt.ylabel('Profit Percentage')\n",
        "plt.title('Profit Percentage vs Maximum Clique Size')\n",
        "\n",
        "# plt.savefig(\"cliquesize2.pdf\",bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVp-s8AEQOH"
      },
      "source": [
        "## profits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXdZsTf4EVFT"
      },
      "outputs": [],
      "source": [
        "no_packing_list=[]\n",
        "two_packing_offline=[]\n",
        "two_packing_online=[]\n",
        "k_packing_offline=[]\n",
        "k_packing_online=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxl58LiPUkzY",
        "outputId": "1cf4eceb-634f-41a3-b4d9-1f4a7cd8fb1e"
      },
      "outputs": [],
      "source": [
        "print(no_packing(expiry))\n",
        "print(k_packing(threshold, alpha, expiry, 2))\n",
        "print(online_k_packing(250, threshold, alpha, expiry-3, 2))\n",
        "print(k_packing(threshold, alpha, expiry, max_clique_size))\n",
        "print(online_k_packing(250, threshold, alpha, expiry-3, max_clique_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQBwWRZ7OB5c"
      },
      "outputs": [],
      "source": [
        "no_packing_list.append(no_packing())\n",
        "two_packing_offline.append(k_packing(threshold, alpha, expiry, 2))\n",
        "two_packing_online.append(online_k_packing(300, threshold, alpha, expiry-3, 2))\n",
        "k_packing_offline.append(k_packing(threshold, alpha, expiry, max_clique_size))\n",
        "k_packing_online.append(online_k_packing(300, threshold, alpha, expiry-3, max_clique_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ2Y63wSPwWV",
        "outputId": "cc607f91-ed94-400d-f022-8c19dddea7d4"
      },
      "outputs": [],
      "source": [
        "print(no_packing_list)\n",
        "print(two_packing_offline)\n",
        "print(two_packing_online)\n",
        "print(k_packing_offline)\n",
        "print(k_packing_online)\n",
        "\n",
        "\n",
        "# total cost\n",
        "# [190800, 1541250, 1477450, 1678700]\n",
        "# [189626.0, 1531872.0, 1452154.0, 1658336.0]\n",
        "# [183950.0, 1516127.0, 1466624.0, 1651008.0]\n",
        "# [169394.0, 1507564.0, 1438902.0, 1630640.0]\n",
        "# [183950.0, 1510494.0, 1442575.0, 1647093.0]\n",
        "\n",
        "# total cost per request\n",
        "# [2051.6129032258063, 711.2367328103369, 681.1664361456892, 775.3810623556582]\n",
        "# [2038.989247311828, 706.9090909090909, 669.503918856616, 765.9750577367206]\n",
        "# [1977.9569892473119, 699.6432856483618, 676.1751959428308, 762.5903002309469]\n",
        "# [1821.4408602150538, 695.6917397323489, 663.3941908713693, 753.1824480369515]\n",
        "# [1977.9569892473119, 697.0438394093217, 665.0875979714154, 760.781986143187]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMzMR2Lwc1E7"
      },
      "outputs": [],
      "source": [
        "# no_packing_list=[190800, 1541250, 1477450, 1678700]\n",
        "# two_packing_offline=[189626.0, 1531872.0, 1452154.0, 1658336.0]\n",
        "# two_packing_online=[183950.0, 1516127.0, 1466624.0, 1651008.0]\n",
        "# k_packing_offline=[169394.0, 1507564.0, 1438902.0, 1630640.0]\n",
        "# k_packing_online=[183950.0, 1510494.0, 1442575.0, 1647093.0]\n",
        "\n",
        "# num_requests_list = [93, 2167, 2169, 2165]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55X67SlMymze"
      },
      "outputs": [],
      "source": [
        "# for i in range(4):\n",
        "#   no_packing_list[i]/=num_requests_list[i]\n",
        "#   two_packing_offline[i]/=num_requests_list[i]\n",
        "#   two_packing_online[i]/=num_requests_list[i]\n",
        "#   k_packing_offline[i]/=num_requests_list[i]\n",
        "#   k_packing_online[i]/=num_requests_list[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "jLH2ymPFbSzZ",
        "outputId": "37e3a68f-f784-422c-d128-6f644df4140d"
      },
      "outputs": [],
      "source": [
        "# set width of bar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "barWidth = 0.12\n",
        "fig = plt.subplots(figsize =(7, 3))\n",
        "\n",
        "br1 = np.arange(len(no_packing_list))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "br4 = [x + barWidth for x in br3]\n",
        "br5 = [x + barWidth for x in br4]\n",
        "\n",
        "plt.ylim(1400000, 1700000)\n",
        "plt.rcParams['hatch.linewidth'] = 2\n",
        "plt.bar(br1, no_packing_list, color = 'none', width = barWidth, edgecolor = 'green', label ='No Packing', fill=False, hatch='//')\n",
        "\n",
        "plt.bar(br2, two_packing_offline, color ='#207c9e', width = barWidth, edgecolor ='black', label ='2 Packing Offline')\n",
        "\n",
        "plt.bar(br3, two_packing_online, color = 'none', width = barWidth, edgecolor = 'red', label ='2 Packing Online', fill=False, hatch='\\\\\\\\')\n",
        "\n",
        "plt.bar(br4, k_packing_offline, color ='grey', width = barWidth, edgecolor ='black', label ='K Packing Offline')\n",
        "\n",
        "plt.bar(br5, k_packing_online, color = 'none', width = barWidth, edgecolor = '#ed09c0', label ='K Packing Online', fill=False, hatch='x')\n",
        "\n",
        "\n",
        "# Adding Xticks\n",
        "plt.xlabel('Dataset', fontweight ='bold', fontsize = 12)\n",
        "plt.ylabel('Cost (1e6)', fontweight ='bold', fontsize = 12)\n",
        "plt.xticks([r + barWidth for r in range(len(no_packing_list))],\n",
        "\t\t['Spotify', 'Netflix 1', 'Netflix 2', 'Netflix 3'])\n",
        "\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=11,bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"upper left\",\n",
        "                mode=\"expand\", borderaxespad=0, ncol=3,edgecolor='k')\n",
        "#plt.show()\n",
        "\n",
        "# plt.savefig('hard_P2.pdf',bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE04NC6HFxR1"
      },
      "outputs": [],
      "source": [
        "no_packing_list_netflix = [1541250, 1477450, 1678700]\n",
        "two_packing_offline_netflix = [1531872.0, 1452154.0, 1658336.0]\n",
        "two_packing_online_netflix = [1516127.0, 1466624.0, 1651008.0]\n",
        "k_packing_offline_netflix = [1507564.0, 1438902.0, 1630640.0]\n",
        "k_packing_online_netflix = [1510494.0, 1442575.0, 1647093.0]\n",
        "\n",
        "no_packing_list_spotify = [190800]\n",
        "two_packing_offline_spotify = [189626]\n",
        "two_packing_online_spotify = [183950]\n",
        "k_packing_offline_spotify = [169394]\n",
        "k_packing_online_spotify = [183950]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "Yos7UnbRHpgm",
        "outputId": "02f9f62a-7474-476e-f363-eba740a39807"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Netflix data\n",
        "no_packing_list_netflix = [1541250, 1477450, 1678700]\n",
        "two_packing_offline_netflix = [1531872.0, 1452154.0, 1658336.0]\n",
        "two_packing_online_netflix = [1516127.0, 1466624.0, 1651008.0]\n",
        "k_packing_offline_netflix = [1507564.0, 1438902.0, 1630640.0]\n",
        "k_packing_online_netflix = [1510494.0, 1442575.0, 1647093.0]\n",
        "\n",
        "# Spotify data\n",
        "no_packing_list_spotify = [190800]\n",
        "two_packing_offline_spotify = [189626]\n",
        "two_packing_online_spotify = [183950]\n",
        "k_packing_offline_spotify = [169394]\n",
        "k_packing_online_spotify = [183950]\n",
        "\n",
        "# Set width of bar\n",
        "barWidth = 0.12\n",
        "\n",
        "# Plotting both graphs horizontally\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5), gridspec_kw={'width_ratios': [4, 1]})\n",
        "\n",
        "# Plotting Netflix dataset\n",
        "br1 = np.arange(len(no_packing_list_netflix))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "br4 = [x + barWidth for x in br3]\n",
        "br5 = [x + barWidth for x in br4]\n",
        "\n",
        "axs[0].bar(br1, no_packing_list_netflix, color='none', width=barWidth, edgecolor='green', label='No Packing', fill=False, hatch='//')\n",
        "axs[0].bar(br1, no_packing_list_netflix, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "axs[0].bar(br2, two_packing_offline_netflix, color='#207c9e', width=barWidth, edgecolor='black', label='2 Packing Offline')\n",
        "\n",
        "axs[0].bar(br3, two_packing_online_netflix, color='none', width=barWidth, edgecolor='red', label='2 Packing Online', fill=False, hatch='\\\\\\\\')\n",
        "axs[0].bar(br3, two_packing_online_netflix, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "axs[0].bar(br4, k_packing_offline_netflix, color='grey', width=barWidth, edgecolor='black', label='K Packing Offline')\n",
        "\n",
        "axs[0].bar(br5, k_packing_online_netflix, color='none', width=barWidth, edgecolor='#ed09c0', label='K Packing Online', fill=False, hatch='x')\n",
        "axs[0].bar(br5, k_packing_online_netflix, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "# Adding x-axis labels and adjusting their position\n",
        "axs[0].set_xticks([r + 2 * barWidth for r in range(len(no_packing_list_netflix))])\n",
        "axs[0].set_xticklabels(['Netflix 1', 'Netflix 2', 'Netflix 3'])\n",
        "\n",
        "axs[0].set_ylabel('Cost (1e6)', fontweight='bold', fontsize=12)\n",
        "axs[0].set_title('Netflix Datasets', color=\"black\")\n",
        "\n",
        "# Plotting Spotify dataset\n",
        "br1_spotify = np.arange(len(no_packing_list_spotify))\n",
        "br2_spotify = [x + 1 * barWidth for x in br1_spotify]  # Adjusted position to align with Netflix bars\n",
        "br3_spotify = [x + 1 * barWidth for x in br2_spotify]  # Adjusted position to align with Netflix bars\n",
        "br4_spotify = [x + 1 * barWidth for x in br3_spotify]  # Adjusted position to align with Netflix bars\n",
        "br5_spotify = [x + 1 * barWidth for x in br4_spotify]  # Adjusted position to align with Netflix bars\n",
        "\n",
        "axs[1].bar(br1_spotify, no_packing_list_spotify, color='none', width=barWidth, edgecolor='green', fill=False, hatch='//')\n",
        "axs[1].bar(br1_spotify, no_packing_list_spotify, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "axs[1].bar(br2_spotify, two_packing_offline_spotify, color='#207c9e', width=barWidth, edgecolor='black')\n",
        "\n",
        "axs[1].bar(br3_spotify, two_packing_online_spotify, color='none', width=barWidth, edgecolor='red', fill=False, hatch='\\\\\\\\')\n",
        "axs[1].bar(br3_spotify, two_packing_online_spotify, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "axs[1].bar(br4_spotify, k_packing_offline_spotify, color='grey', width=barWidth, edgecolor='black')\n",
        "\n",
        "axs[1].bar(br5_spotify, k_packing_online_spotify, color='none', width=barWidth, edgecolor='#ed09c0', fill=False, hatch='x')\n",
        "axs[1].bar(br5_spotify, k_packing_online_spotify, color='none', width=barWidth, edgecolor='k')\n",
        "\n",
        "# Adding x-axis labels and adjusting their position\n",
        "axs[1].set_xticks([r + 2* barWidth for r in range(len(no_packing_list_spotify))])  # Adjusted position to align with Netflix bars\n",
        "axs[1].set_xticklabels(['Spotify'])\n",
        "\n",
        "axs[1].set_ylabel('Cost', fontweight='bold', fontsize=12)\n",
        "axs[1].set_title('Spotify Dataset', color=\"black\")\n",
        "\n",
        "# Adjust y-axis limits\n",
        "axs[0].set_ylim(1.4e6, 1.7e6)\n",
        "axs[1].set_ylim(1.4e5, 2.0e5)\n",
        "\n",
        "# Adding global and subheadings\n",
        "fig.suptitle('Cost vs Dataset', fontsize=16, fontweight='bold')\n",
        "plt.figlegend(handles=axs[0].containers, labels=axs[0].get_legend_handles_labels()[1], fontsize=11, bbox_to_anchor=(0.5, 0.94), loc='upper center', ncol=3)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.9])  # Adjusts the subplot layout to fit the figure area\n",
        "plt.savefig(\"combined_plots_horizontal.pdf\", bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CZYPYlAI89_"
      },
      "source": [
        "## batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfp7XcnMJBYO",
        "outputId": "b14ac466-9778-46e8-b512-b361c7baaad2"
      },
      "outputs": [],
      "source": [
        "values = [50,100,150,200,250,300,350,400,450,500]\n",
        "generated_results_2 = []\n",
        "\n",
        "for elmt in values:\n",
        "  total_cost_online = online_k_packing(elmt, threshold, alpha, expiry)\n",
        "  generated_results_2.append(100*(total_cost-total_cost_online)/total_cost)\n",
        "\n",
        "print(generated_results_2)\n",
        "# [8.335055581650227, 8.425238766243933, 8.387662439329889, 7.110693596367621, 8.110223892281196, 5.533114138093001, 8.23547831532801, 8.86801315171442, 7.142007202129325, 6.954751839674339]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "r6NjtYvEJNDc",
        "outputId": "cd2685ca-dd1c-4b1c-e57c-41c67701dd05"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = values\n",
        "y1 = generated_results_2\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "# plotting the points\n",
        "f = plt.figure()\n",
        "f.set_figwidth(7)\n",
        "f.set_figheight(3)\n",
        "plt.plot(x, y1, color='magenta', linewidth=2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, linestyle='dashed')\n",
        "\n",
        "\n",
        "plt.ylabel('Profit percentage')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.title('Profit Percentage vs Batch Size',color=\"black\")\n",
        "\n",
        "plt.savefig(\"batchsize.pdf\",bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTLdv9TyQlHy"
      },
      "source": [
        "## Netflix Viral Dataset Gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3KgnjVpQlHy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/Netflix4/netflix_viral_100_set_4.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU7W1AdfQlHz"
      },
      "outputs": [],
      "source": [
        "# df[['userid', 'dataid', 'timestamp', 'location']] = df['userid dataid timestamp location'].str.split(' ', 3, expand=True)\n",
        "\n",
        "# # Drop the original concatenated column\n",
        "# df.drop(columns=['userid dataid timestamp location'], inplace=True)\n",
        "\n",
        "# Convert 'userid' and 'dataid' columns to integers, and 'timestamp' to datetime\n",
        "df['userid'] = df['userid'].astype(int)\n",
        "df['dataid'] = df['dataid'].astype(int)\n",
        "df['timestamp'] = df['timestamp'].astype(int)\n",
        "df['location'] = df['location'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adr-zAfRQlHz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['dataid'].unique()\n",
        "\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['dataid'] = (df['dataid'].map(mapping_dict)).astype(int)\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPRD-G6AQlHz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "# Initialize the 3D array with zeros\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=object)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "    location = row['location']\n",
        "    timestamp = row['timestamp']\n",
        "    dataid = row['dataid']\n",
        "\n",
        "    if(dataid == 0):\n",
        "      continue\n",
        "\n",
        "    # Check if the current list would exceed max_request_size\n",
        "    if isinstance(result_array[location, timestamp], list) and len(result_array[location, timestamp]) >= max_request_size:\n",
        "        # If it exceeds, ignore this element\n",
        "        continue\n",
        "\n",
        "    if result_array[location, timestamp] == 0:  # If the cell is empty\n",
        "        result_array[location, timestamp] = [dataid]  # Initialize as a list\n",
        "    else:\n",
        "        result_array[location, timestamp].append(dataid)  # Append to existing list\n",
        "\n",
        "# Convert empty cells to None for uniformity\n",
        "result_array[result_array == 0] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGDPHvFLQlHz"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDinkbi4R0wr",
        "outputId": "20b75897-0192-4e87-fcda-c9ccf97be124"
      },
      "outputs": [],
      "source": [
        "total_cost=no_packing(expiry)\n",
        "total_cost_k = k_packing(threshold, alpha, expiry, max_clique_size)\n",
        "ViralDataset4.append((100*(total_cost-total_cost_k))/total_cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otBepdppVWqX",
        "outputId": "59936cb4-29f1-4730-b801-90c73aad0121"
      },
      "outputs": [],
      "source": [
        "ViralDataset4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMsuj8YqEEbd"
      },
      "source": [
        "## Spotify Viral Dataset Gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYCdfygVEEbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.read_csv('/content/drive/My Drive/BTP/viral_100.csv')\n",
        "df = df_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5vG_KTKEEbn",
        "outputId": "2205e430-7735-4f4c-8cea-5328d14156d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sort the DataFrame by 'plays' in descending order\n",
        "df.sort_values(['location', 'timestamp', 'plays'], ascending=[True, True, False], inplace=True)\n",
        "\n",
        "# Keep only the rows with the maximum 'plays' for each group of 'location' and 'timestamp'\n",
        "# result_df = df.groupby(['location', 'timestamp']).first().reset_index()\n",
        "\n",
        "# result_df = result_df.drop(['plays'], axis=1)\n",
        "\n",
        "\n",
        "# Display the result\n",
        "# print(result_df.head(100))\n",
        "\n",
        "\n",
        "# print(\"Count of Unique Locations:\", result_df['location'].nunique())\n",
        "print(\"Count of Unique Data IDs:\", df['dataid'].nunique())\n",
        "# print(\"Count of Unique Timestamps:\", result_df['timestamp'].nunique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwHL_72gEEbn",
        "outputId": "0b12d3e9-ef9e-49bb-d922-681136eef380"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['dataid'].unique()\n",
        "\n",
        "print(unique_dataids)\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "print(unique_dataids)\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['dataid'] = (df['dataid'].map(mapping_dict)).astype(int)\n",
        "\n",
        "print(df['dataid'])\n",
        "\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6E-bBmIEEbo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is loaded into a DataFrame called df\n",
        "\n",
        "# Get the unique values in the 'dataid' column\n",
        "unique_dataids = df['location'].unique()\n",
        "\n",
        "# Sort the unique dataids\n",
        "unique_dataids.sort()\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping_dict = {dataid: idx + 1 for idx, dataid in enumerate(unique_dataids)}\n",
        "\n",
        "# Update the 'dataid' column using the mapping dictionary\n",
        "df['location'] = (df['location'].map(mapping_dict)).astype(int)\n",
        "\n",
        "# Now 'dataid' values will be mapped to [1 to N] in ascending order where N is the number of unique data points\n",
        "\n",
        "# Save the updated DataFrame or use it for further analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-W6dXzvEEbo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_locations = max(df['location'])+1\n",
        "num_timestamps = max(df['timestamp'])+1\n",
        "# Initialize the 3D array with zeros\n",
        "result_array = np.zeros((num_locations, num_timestamps), dtype=object)\n",
        "\n",
        "# Iterate through the DataFrame and populate the array\n",
        "for index, row in df.iterrows():\n",
        "    location = row['location']\n",
        "    timestamp = row['timestamp']\n",
        "    dataid = row['dataid']\n",
        "\n",
        "    if(dataid == 0):\n",
        "      continue\n",
        "\n",
        "    # Check if the current list would exceed max_request_size\n",
        "    if isinstance(result_array[location, timestamp], list) and len(result_array[location, timestamp]) >= max_request_size:\n",
        "        # If it exceeds, ignore this element\n",
        "        continue\n",
        "\n",
        "    if result_array[location, timestamp] == 0:  # If the cell is empty\n",
        "        result_array[location, timestamp] = [dataid]  # Initialize as a list\n",
        "    else:\n",
        "        result_array[location, timestamp].append(dataid)  # Append to existing list\n",
        "\n",
        "# Convert empty cells to None for uniformity\n",
        "result_array[result_array == 0] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR9Dqfq_EEbo"
      },
      "outputs": [],
      "source": [
        "requests = result_array\n",
        "num_requests = num_timestamps\n",
        "num_data_pts = max(df['dataid'])\n",
        "num_servers = num_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl7qUzzucate",
        "outputId": "0e2cb5a4-6b8d-492c-c540-50637f4c8d11"
      },
      "outputs": [],
      "source": [
        "total_cost=no_packing(expiry)\n",
        "total_cost_k = k_packing(threshold, alpha, expiry, max_clique_size)\n",
        "SpotifyViral.append((100*(total_cost-total_cost_k))/total_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNNZADDsDmsG"
      },
      "source": [
        "## Graph plotting netflix and Spotify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cuye1tTPDrR3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate x-axis values from 10 to 100 with a step of 10\n",
        "x = np.arange(10, 101, 10)\n",
        "\n",
        "# Sample data for the arrays\n",
        "SpotifyViral = [27.634422948632423, 14.514285714285714, 10.498819826907946, 12.444739462329904, 14.075160403299725, 13.395375070501974, 12.868362831858407, 12.814834721848966, 11.670026525198939, 11.219077568134171]\n",
        "ViralDataset2 = [13.509341199606686, 6.517402749341913, 5.487093607437778, 3.2581684307409113, 3.436082569656577, 2.9517774851876233, 3.373592158370171, 2.2316687400035544, 1.974151418270866, 2.1856285482562856]\n",
        "ViralDataset3 = [14.76009139375476, 9.422648054844306, 5.530847081658117, 6.284882663270875, 5.989597780859917, 4.303238469087341, 3.561466325660699, 3.445600829524943, 2.8004358881220486, 2.609089986124742]\n",
        "ViralDataset4 = [18.70174224068305, 14.58558766859345, 7.918999270769058, 5.985172672672673, 5.613025302530253, 4.004594884362077, 3.601591340812157, 3.1568784125715807, 3.399854793396256, 2.8629296479418596]\n",
        "\n",
        "# Plotting both graphs horizontally\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plotting the Netflix datasets first\n",
        "axs[0].plot(x, ViralDataset2, label='Netflix1', color='blue', linewidth=2,\n",
        "            marker='o', markerfacecolor='black', markersize=3, linestyle='dashed')\n",
        "axs[0].plot(x, ViralDataset3, label='Netflix2', color='green', linewidth=2,\n",
        "            marker='o', markerfacecolor='black', markersize=3, linestyle='dashed')\n",
        "axs[0].plot(x, ViralDataset4, label='Netflix3', color='red', linewidth=2,\n",
        "            marker='o', markerfacecolor='black', markersize=3, linestyle='dashed')\n",
        "\n",
        "axs[0].set_ylabel('Profit Percentage')\n",
        "axs[0].set_xlabel('#Top Movies')\n",
        "axs[0].set_title('Netflix Datasets: Profit Percentage vs #Top Movies', color=\"black\")\n",
        "axs[0].legend()\n",
        "\n",
        "# Plotting the SpotifyViral dataset to the right\n",
        "axs[1].plot(x, SpotifyViral, label='SpotifyViral', color='magenta', linewidth=2,\n",
        "            marker='o', markerfacecolor='black', markersize=3, linestyle='dashed')\n",
        "axs[1].set_ylabel('Profit Percentage')\n",
        "axs[1].set_xlabel('#Top Songs')\n",
        "axs[1].set_title('SpotifyViral: Profit Percentage vs #Top Songs', color=\"black\")\n",
        "axs[1].legend()\n",
        "\n",
        "# Set x-axis ticks for both plots\n",
        "for ax in axs:\n",
        "    ax.set_xticks(x)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"combined_plots.pdf\", bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "vT7FT38AO3_7",
        "outputId": "fcc3cc09-8b08-4923-a875-2251bd744706"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate x-axis values from 10 to 100 with a step of 10\n",
        "x = np.arange(10, 101, 10)\n",
        "\n",
        "# Sample data for the arrays\n",
        "SpotifyViral = [27.634422948632423, 14.514285714285714, 10.498819826907946, 12.444739462329904, 14.075160403299725, 13.395375070501974, 12.868362831858407, 12.814834721848966, 11.670026525198939, 11.219077568134171]\n",
        "Netflix1 = [13.509341199606686, 6.517402749341913, 5.487093607437778, 3.2581684307409113, 3.436082569656577, 2.9517774851876233, 3.373592158370171, 2.2316687400035544, 1.974151418270866, 2.1856285482562856]\n",
        "Netflix2 = [14.76009139375476, 9.422648054844306, 5.530847081658117, 6.284882663270875, 5.989597780859917, 4.303238469087341, 3.561466325660699, 3.445600829524943, 2.8004358881220486, 2.609089986124742]\n",
        "Netflix3 = [18.70174224068305, 14.58558766859345, 7.918999270769058, 5.985172672672673, 5.613025302530253, 4.004594884362077, 3.601591340812157, 3.1568784125715807, 3.399854793396256, 2.8629296479418596]\n",
        "\n",
        "# Plotting all datasets on a single graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(x, SpotifyViral, label='SpotifyViral', color='magenta', linewidth=2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, linestyle='-')\n",
        "plt.plot(x, Netflix1, label='Netflix1', color='blue', linewidth=2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, linestyle='-.')\n",
        "plt.plot(x, Netflix2, label='Netflix2', color='green', linewidth=2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, linestyle='--')\n",
        "plt.plot(x, Netflix3, label='Netflix3', color='red', linewidth=2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, linestyle=':')\n",
        "\n",
        "plt.ylabel('Profit Percentage')\n",
        "plt.xlabel('Top Trending')\n",
        "plt.title('Profit Percentage vs Top Trending')\n",
        "plt.legend()\n",
        "plt.xticks(x)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"viral_plot.pdf\", bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45dSe1TtLdNr"
      },
      "source": [
        "## expiry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN7yD2rULcHh",
        "outputId": "457de64d-b998-4246-9de1-1a570dbee8a5"
      },
      "outputs": [],
      "source": [
        "values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
        "generated_results = []\n",
        "generated_results_2 = []\n",
        "\n",
        "for elmt in values:\n",
        "  total_cost=no_packing(elmt)\n",
        "  total_cost_k = k_packing(threshold, alpha, elmt, max_clique_size)\n",
        "  generated_results.append((100*(total_cost-total_cost_k))/total_cost)\n",
        "  total_cost_online = online_k_packing(batch_size, threshold, alpha, elmt, max_clique_size)\n",
        "  generated_results_2.append(100*(total_cost-total_cost_online)/total_cost)\n",
        "\n",
        "print(generated_results)\n",
        "print(generated_results_2)\n",
        "\n",
        "# [6.777453253353352, 14.472748341724607, 16.034030295262856, 16.502862080138243, 16.78943350221946, 15.774490415810359, 15.604209341664179, 14.37494355435941]\n",
        "# [3.224030881532895, 6.599736274274754, 7.285022031808805, 7.00385764647564, 7.1780124144881965, 6.600359326327762, 6.353813900983712, 6.0220725032964255]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "CqDFqruqyfcA",
        "outputId": "3db7e1a5-6d4c-4956-c9c3-f49a287df974"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = values\n",
        "y = generated_results\n",
        "y1 = generated_results_2\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "# plotting the points\n",
        "f = plt.figure()\n",
        "f.set_figwidth(7)\n",
        "f.set_figheight(3)\n",
        "plt.plot(x, y, color='g',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Offline', linestyle='dotted')\n",
        "\n",
        "plt.plot(x, y1, color='magenta',linewidth = 2,\n",
        "         marker='o', markerfacecolor='black', markersize=3, label='Online',linestyle='dashed')\n",
        "\n",
        "\n",
        "plt.ylabel('Profit percentage')\n",
        "plt.xlabel('Expiry')\n",
        "plt.title('Profit Percentage vs Expiry',color=\"black\")\n",
        "plt.legend(fontsize=12,edgecolor='k',ncol=2)\n",
        "\n",
        "plt.savefig(\"Expiry.pdf\",bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jxR2Bzd5FvU"
      },
      "source": [
        "##CliqueSize printing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wdHg1nwF5KKB",
        "outputId": "71acf052-0008-49b2-c4ff-22364575bb5a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data points\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "y = [0, 2, 2, 1, 1, 1, 2, 1, 0]\n",
        "\n",
        "# Create a bar graph with a different shade of blue\n",
        "plt.bar(x, y)  # Use hex color code for a specific shade of blue\n",
        "\n",
        "# Set the y-axis limit\n",
        "plt.ylim(0, 5)\n",
        "\n",
        "# Set x-axis ticks with step size 1\n",
        "plt.xticks(range(1, 11, 1))\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Frequency of Cliques vs Clique Size')\n",
        "plt.xlabel('Clique Size')\n",
        "plt.ylabel('Number of Cliques')\n",
        "\n",
        "plt.savefig(\"cs1.pdf\",bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WSpTJEQK7ot2",
        "outputId": "77b89dd0-4445-4e68-e88a-87f8014bc305"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data points\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "y = [0, 4, 2, 1, 1, 4, 0, 0, 0]\n",
        "\n",
        "# Create a bar graph with a different shade of blue\n",
        "plt.bar(x, y)  # Use hex color code for a specific shade of blue\n",
        "\n",
        "# Set the y-axis limit\n",
        "plt.ylim(0, 5)\n",
        "\n",
        "# Set x-axis ticks with step size 1\n",
        "plt.xticks(range(1, 11, 1))\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Frequency of Cliques vs Clique Size (max_clique_size = 6)')\n",
        "plt.xlabel('Clique Size')\n",
        "plt.ylabel('Number of Cliques')\n",
        "\n",
        "plt.savefig(\"cs3.pdf\",bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4wwxU8s-hws"
      },
      "source": [
        "#Clique Efficacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUx2gkrl-hwt",
        "outputId": "4630ace0-2d28-4fd2-f17b-bb6e668313c9"
      },
      "outputs": [],
      "source": [
        "for clique_index, clique in enumerate(independent_cliques):\n",
        "  print(clique_index)\n",
        "  print(clique)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxBHkFh5fnkW",
        "outputId": "e1db8a90-9504-40c9-db5e-60b043507ae0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example array\n",
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6],\n",
        "                [7, 8, 9]])\n",
        "\n",
        "# Value to search for\n",
        "data_point = 2740\n",
        "\n",
        "# Find indices of data point\n",
        "indices = np.where(requests == data_point)\n",
        "\n",
        "# Print the indices\n",
        "for i, j in zip(indices[0], indices[1]):\n",
        "    print(f\"Indices of {data_point}: ({i}, {j})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUJHKhAB-hwu",
        "outputId": "ddca58ba-1a42-44ec-f579-3c2b8a0950d7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'requests' is a 2D numpy array and 'independent_cliques' is a list of lists or numpy arrays\n",
        "\n",
        "num_servers = len(requests)\n",
        "num_cliques = len(independent_cliques)\n",
        "\n",
        "for server_index in range(num_servers):\n",
        "    print(f\"Server {server_index}:\")\n",
        "    server_data_points = requests[server_index]\n",
        "\n",
        "    for clique_index, clique in enumerate(independent_cliques):\n",
        "        clique_data_point_counts = np.zeros(len(clique), dtype=int)\n",
        "\n",
        "        for data_point_index, data_point in enumerate(clique):\n",
        "            count = np.sum(server_data_points == data_point+1)\n",
        "            clique_data_point_counts[data_point_index] = count\n",
        "\n",
        "        print(f\"  Clique {clique_index}: {clique_data_point_counts}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0d_V5l6-hwu",
        "outputId": "3c1cfe52-efa6-4b10-9d09-aeb8b5e0b5a9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'requests' is a 2D numpy array and 'independent_cliques' is a list of lists or numpy arrays\n",
        "\n",
        "num_servers = len(requests)\n",
        "num_cliques = len(independent_cliques)\n",
        "\n",
        "# Create a 2D array to store percentages found at each server for each clique\n",
        "percentages = np.zeros((num_cliques, num_servers), dtype=int)\n",
        "\n",
        "for server_index in range(num_servers):\n",
        "    server_data_points = requests[server_index]\n",
        "\n",
        "    for clique_index, clique in enumerate(independent_cliques):\n",
        "        clique_data_point_counts = np.zeros(len(clique), dtype=int)\n",
        "\n",
        "        for data_point_index, data_point in enumerate(clique):\n",
        "            count = np.sum(server_data_points == data_point+1)\n",
        "            clique_data_point_counts[data_point_index] = count\n",
        "\n",
        "        non_zero_count = np.count_nonzero(clique_data_point_counts)\n",
        "        clique_size = len(clique)\n",
        "        percentage_non_zero = int(round((non_zero_count / clique_size) * 100))\n",
        "\n",
        "        percentages[clique_index, server_index] = percentage_non_zero\n",
        "\n",
        "# Calculate average percentage of each clique\n",
        "average_percentages = np.mean(percentages, axis=1)\n",
        "\n",
        "print(\"Percentages found at each server for each clique:\")\n",
        "print(percentages)\n",
        "print(\"\\nAverage percentage of each clique:\")\n",
        "print(average_percentages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa1q6E8hbpqt",
        "outputId": "8648a66d-354a-43b1-e99b-7f912bc618a1"
      },
      "outputs": [],
      "source": [
        "for clique_index, clique in enumerate(independent_cliques):\n",
        "  print(clique_index)\n",
        "  print(clique)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVDYtb7DcnNk",
        "outputId": "5c384415-1d04-41db-db42-6f873ab7f9b1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'requests' is a 2D numpy array and 'independent_cliques' is a list of lists or numpy arrays\n",
        "\n",
        "num_servers = len(requests)\n",
        "num_cliques = len(independent_cliques)\n",
        "\n",
        "for server_index in range(num_servers):\n",
        "    print(f\"Server {server_index}:\")\n",
        "    server_data_points = requests[server_index]\n",
        "\n",
        "    for clique_index, clique in enumerate(independent_cliques):\n",
        "        clique_data_point_counts = np.zeros(len(clique), dtype=int)\n",
        "\n",
        "        for data_point_index, data_point in enumerate(clique):\n",
        "            count = np.sum(server_data_points == data_point)\n",
        "            clique_data_point_counts[data_point_index] = count\n",
        "\n",
        "        print(f\"  Clique {clique_index}: {clique_data_point_counts}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2dfvc_wCmH0",
        "outputId": "e3d50639-94a5-4f17-9218-fbcaad07e35a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'requests' is a 2D numpy array and 'independent_cliques' is a list of lists or numpy arrays\n",
        "\n",
        "num_servers = len(requests)\n",
        "num_cliques = len(independent_cliques)\n",
        "\n",
        "# Create a 2D array to store percentages found at each server for each clique\n",
        "percentages = np.zeros((num_cliques, num_servers), dtype=int)\n",
        "\n",
        "for server_index in range(num_servers):\n",
        "    server_data_points = requests[server_index]\n",
        "\n",
        "    for clique_index, clique in enumerate(independent_cliques):\n",
        "        clique_data_point_counts = np.zeros(len(clique), dtype=int)\n",
        "\n",
        "        for data_point_index, data_point in enumerate(clique):\n",
        "            count = np.sum(server_data_points == data_point)\n",
        "            clique_data_point_counts[data_point_index] = count\n",
        "\n",
        "        non_zero_count = np.count_nonzero(clique_data_point_counts)\n",
        "        clique_size = len(clique)\n",
        "        percentage_non_zero = int(round((non_zero_count / clique_size) * 100))\n",
        "\n",
        "        percentages[clique_index, server_index] = percentage_non_zero\n",
        "\n",
        "# Calculate average percentage of each clique\n",
        "average_percentages = np.mean(percentages, axis=1)\n",
        "\n",
        "print(\"Percentages found at each server for each clique:\")\n",
        "print(percentages)\n",
        "print(\"\\nAverage percentage of each clique:\")\n",
        "print(average_percentages)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onb4YQyAW3nM"
      },
      "source": [
        "# GENERATED RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVxzvjWCWbxx"
      },
      "outputs": [],
      "source": [
        "generated_results.append((total_cost, total_cost_2, total_cost_k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrgkCawWrnd",
        "outputId": "4b26ebd4-3c8a-469c-e216-33f0c4cc7f2b"
      },
      "outputs": [],
      "source": [
        "generated_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prwBQH4Y0kbC",
        "outputId": "15e2b66e-eb3a-43a4-a856-f5366379b79d"
      },
      "outputs": [],
      "source": [
        "last_element = generated_results[-1]\n",
        "print(100*(last_element[0]-last_element[2])/last_element[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "DO6EDMKPlqLS",
        "outputId": "bb65f23c-3d5b-4c31-abe0-4af8f526274c"
      },
      "outputs": [],
      "source": [
        "# @title netflix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "generated_results = [(438177.0, 431380.0, 318460.0, 407637.0)]\n",
        "# generated_results = [(1704251, 1695246.0, 1471421.0, 1483151.0),\n",
        "#   (1565066, 1552219.0, 1350746.0, 1361666.0),\n",
        "#   (1562424, 1561189.0, 1343686.0, 1354524.0)]\n",
        "\n",
        "Dataset = ['Spotify']\n",
        "# Dataset = ['Netflix 1', 'Netflix 2', 'Netflix 3']\n",
        "\n",
        "# Transpose the data for easier plotting\n",
        "data = np.array(generated_results).T\n",
        "\n",
        "# Set up the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Plot each set with bars close to each other\n",
        "bar_width = 0.2\n",
        "bar_positions = np.arange(len(Dataset))\n",
        "\n",
        "legend_labels = ['No packing', '2 packing', 'K packing (offline)', 'K packing (online)' ]\n",
        "\n",
        "for i, set_data in enumerate(data):\n",
        "    ax.bar(bar_positions + i * bar_width, set_data, width=bar_width, label=f'{legend_labels[i]}')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Dataset')\n",
        "ax.set_ylabel('Total Cost')\n",
        "ax.set_title('Total Cost vs Dataset')\n",
        "ax.set_xticks(bar_positions + bar_width)\n",
        "ax.set_xticklabels([f'{std}%' for std in Dataset])\n",
        "ax.legend()\n",
        "\n",
        "ax.set_ylim(300000.0, max(map(max, generated_results)) + 1000)\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75246fplS2TI",
        "outputId": "6a8f4b25-9ff3-446e-9406-d031c34f9221"
      },
      "outputs": [],
      "source": [
        "generated_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXH33RmEaMcp"
      },
      "source": [
        "# Printing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_8wQkp0_3qd"
      },
      "outputs": [],
      "source": [
        "generated_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wv3-rwm5fZH"
      },
      "outputs": [],
      "source": [
        "print(\"spotify\")\n",
        "print(generated_results[0])\n",
        "print(generated_results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZrmuuJU51M3"
      },
      "outputs": [],
      "source": [
        "print(\"netflix 1\")\n",
        "print(generated_results[2])\n",
        "print(generated_results[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNtXXp-v53Yt"
      },
      "outputs": [],
      "source": [
        "print(\"netflix 2\")\n",
        "print(generated_results[4])\n",
        "print(generated_results[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JttGmnzd536S"
      },
      "outputs": [],
      "source": [
        "print(\"netflix 3\")\n",
        "print(generated_results[6])\n",
        "print(generated_results[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BARWGhTEneu5"
      },
      "outputs": [],
      "source": [
        "total_cost_online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw-X7kk6dlZ5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-DKELwt3MguZ",
        "Nm3pa7wzTkjO",
        "3J1vNpgb__7S",
        "nRuVTtULj5nY",
        "NAIWxCHHTtGi",
        "3fVZVOYJ127j",
        "dMrCX44Z4yxs",
        "fptZF-2SwTob",
        "U4wwxU8s-hws",
        "ynuHepc2Ejtf",
        "zXH33RmEaMcp"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
